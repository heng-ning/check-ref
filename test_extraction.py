import streamlit as st
import re
import unicodedata
from docx import Document
import fitz
import json
from datetime import datetime


# ==================== 0. æ–‡å­—æ­£è¦åŒ–å·¥å…· ====================

def normalize_text(text):
    """æ­£è¦åŒ–æ–‡å­—ï¼šå…¨å½¢è½‰åŠå½¢ã€æ¸…ç†å„ç¨®ç©ºç™½èˆ‡æ§åˆ¶ç¬¦"""
    if not text:
        return ""
    # 1ï¸âƒ£ å…¨å½¢å­—å…ƒè½‰åŠå½¢ (åŒ…å«æ‹¬è™Ÿã€æ¨™é»ã€ç©ºæ ¼)
    text = unicodedata.normalize('NFKC', text)
    # 2ï¸âƒ£ å°‡å¸¸è¦‹éš±è—ç©ºç™½ï¼ˆNBSPã€å…¨å½¢ç©ºç™½ç­‰ï¼‰çµ±ä¸€ç‚ºä¸€èˆ¬ç©ºç™½
    text = re.sub(r'[\u3000\xa0\u200b\u200c\u200d]+', ' ', text)
    # 3ï¸âƒ£ å»é™¤å¤šé‡ç©ºç™½ã€æ›è¡Œã€tab
    text = re.sub(r'\s+', ' ', text)
    # 4ï¸âƒ£ å»é ­å°¾ç©ºç™½
    return text.strip()

def normalize_citation_for_matching(citation):
    """å°ˆé–€ç”¨æ–¼å¼•ç”¨æ¯”å°çš„æ­£è¦åŒ–"""
    text = normalize_text(citation)
    text = re.sub(r'\s', '', text)
    text = text.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
    text = text.replace('ã€', '[').replace('ã€‘', ']')
    return text.lower()


# ==================== 1. æ–‡ä»¶è®€å–æ¨¡çµ„ ====================

def extract_paragraphs_from_docx(file):
    doc = Document(file)
    return [para.text.strip() for para in doc.paragraphs if para.text.strip()]

# def extract_paragraphs_from_pdf(file):
#     text = ""
#     with fitz.open(stream=file.read(), filetype="pdf") as doc:
#         for page in doc:
#             page_text = page.get_text("text")
#             text += page_text + "\n"
#     paragraphs = [p.strip() for p in text.split("\n") if p.strip()]
#     return paragraphs

def extract_paragraphs_from_pdf(file):
    text = ""
    with fitz.open(stream=file.read(), filetype="pdf") as doc:
        for page in doc:
            text += page.get_text("text") + "\n"
    return [p.strip() for p in text.split("\n") if p.strip()]
# ==================== 2. åƒè€ƒæ–‡ç»å€æ®µè­˜åˆ¥ ====================

def is_appendix_heading(text):
    """åˆ¤æ–·æ˜¯å¦ç‚ºé™„éŒ„æ¨™é¡Œ"""
    text = text.strip()
    pattern = r'^([ã€ã€”ï¼ˆ(]?\s*)?((\d+|[IVXLCDM]+|[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åå£¹è²³åƒè‚†ä¼é™¸æŸ’æŒç–æ‹¾]+)[ã€ï¼. ]?)?\s*(é™„éŒ„|APPENDIX)(\s*[ã€‘ã€•ï¼‰)]?)?$'
    return bool(re.match(pattern, text, re.IGNORECASE))

def is_reference_format(text):
    """åˆ¤æ–·æ®µè½æ˜¯å¦çœ‹èµ·ä¾†åƒåƒè€ƒæ–‡ç»"""
    text = text.strip()
    if len(text) < 10:
        return False
    if re.search(r'\(\d{4}[a-c]?\)', text):
        return True
    if re.match(r'^\[\d+\]', text):
        return True
    if re.search(r'[A-Z][a-z]+,\s*[A-Z]\.', text):
        return True
    return False

def extract_reference_section_improved(paragraphs):
    """æ”¹é€²çš„åƒè€ƒæ–‡ç»å€æ®µè­˜åˆ¥"""
    reference_keywords = [
        "åƒè€ƒæ–‡ç»", "åƒè€ƒè³‡æ–™", "references", "reference",
        "bibliography", "works cited", "literature cited",
        "references and citations"
    ]
    
    def clip_until_stop(paragraphs_after):
        """æˆªå–è‡³é™„éŒ„ç‚ºæ­¢"""
        result = []
        for para in paragraphs_after:
            if is_appendix_heading(para):
                break
            result.append(para)
        return result
    
    for i in reversed(range(len(paragraphs))):
        para = paragraphs[i].strip()
        para_lower = para.lower()
        para_normalized = normalize_text(para_lower)
        
        if len(para) > 50:
            continue
        
        for keyword in reference_keywords:
            if normalize_text(keyword) == para_normalized:
                return clip_until_stop(paragraphs[i + 1:]), para, "ç´”æ¨™é¡Œè­˜åˆ¥"
        
        pattern = r'^((ç¬¬?[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒè¬å£¹è²³åƒè‚†ä¼é™¸æŸ’æŒç–æ‹¾ä½°ä»Ÿè¬]+ç« [ã€ï¼.ï¸‘,ï¼Œ]?)|(\d+|[IVXLCDM]+)?[ã€ï¼.ï¸‘,ï¼Œ ]?)?\s*(åƒè€ƒæ–‡ç»|åƒè€ƒè³‡æ–™|references?|bibliography)\s*$'
        if re.match(pattern, para_lower):
            return clip_until_stop(paragraphs[i + 1:]), para, "ç« ç¯€æ¨™é¡Œè­˜åˆ¥"
        
        fuzzy_keywords = ["reference", "åƒè€ƒ", "bibliography"]
        if any(para_lower.strip() == k for k in fuzzy_keywords):
            if i + 1 < len(paragraphs):
                next_paras = paragraphs[i+1:min(i+6, len(paragraphs))]
                if sum(1 for p in next_paras if is_reference_format(p)) >= 1:
                    return clip_until_stop(paragraphs[i + 1:]), para.strip(), "å…§å®¹ç‰¹å¾µè­˜åˆ¥"
    
    return [], None, "æœªæ‰¾åˆ°åƒè€ƒæ–‡ç»å€æ®µ"


def extract_reference_section(paragraphs):
    """åŸæœ¬çš„ç°¡å–®ç‰ˆæœ¬ï¼ˆfallbackï¼‰"""
    reference_keywords = [
        "åƒè€ƒæ–‡ç»", "åƒè€ƒè³‡æ–™", "references", "reference",
        "bibliography", "works cited", "literature cited"
    ]
    
    for i in reversed(range(len(paragraphs))):
        para = paragraphs[i].strip()
        para_lower = para.lower()
        para_normalized = normalize_text(para_lower)
        
        if len(para) > 50:
            continue
        
        for keyword in reference_keywords:
            if normalize_text(keyword) == para_normalized:
                ref_paragraphs = []
                for p in paragraphs[i + 1:]:
                    if is_appendix_heading(p):
                        break
                    ref_paragraphs.append(p)
                return ref_paragraphs, para, i
        
        pattern = r'^((ç¬¬?[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒè¬å£¹è²³åƒè‚†ä¼é™¸æŸ’æŒç–æ‹¾ä½°ä»Ÿè¬]+ç« [ã€ï¼.ï¸‘,ï¼Œ]?)|(\d+|[IVXLCDM]+)?[ã€ï¼.ï¸‘,ï¼Œ ]?)?\s*(åƒè€ƒæ–‡ç»|åƒè€ƒè³‡æ–™|references?|bibliography)\s*$'
        if re.match(pattern, para_lower):
            ref_paragraphs = []
            for p in paragraphs[i + 1:]:
                if is_appendix_heading(p):
                    break
                ref_paragraphs.append(p)
            return ref_paragraphs, para, i
    
    return [], None, None

def classify_document_sections(paragraphs):
    """å°‡æ–‡ä»¶åˆ†ç‚ºå…§æ–‡æ®µè½å’Œåƒè€ƒæ–‡ç»æ®µè½"""
    ref_paragraphs, ref_keyword, method = extract_reference_section_improved(paragraphs)
    
    if not ref_paragraphs:
        ref_paragraphs, ref_keyword, _ = extract_reference_section(paragraphs)
        if not ref_paragraphs:
            return paragraphs, [], None, None
    
    ref_start_index = None
    for i, para in enumerate(paragraphs):
        if para.strip() == ref_keyword:
            ref_start_index = i
            break
    
    if ref_start_index is None:
        return paragraphs, [], None, None
    
    content_paragraphs = paragraphs[:ref_start_index]
    return content_paragraphs, ref_paragraphs, ref_start_index, ref_keyword


# ==================== 3. å…§æ–‡å¼•ç”¨æ“·å– ====================

def is_valid_year(year_str):
    try:
        year = int(year_str)
        return 1000 <= year <= 2050
    except:
        return False

def extract_in_text_citations(content_paragraphs):
    """
    ä¿®æ­£ï¼šAPA å…§æ–‡å¼•ç”¨ä¸æŠ“æ•¸å­—ä½œè€…ï¼Œæ’é™¤å¦‚ 14(2022)
    """
    full_text = " ".join(content_paragraphs)
    citations = []
    citation_ids = set()
    # APA: (ä½œè€…, å¹´ä»½) and ä½œè€…(å¹´ä»½) å‹å¼
    pattern_apa1 = re.compile(
        r'(?<![0-9])[ï¼ˆ(]\s*([\w\s\u4e00-\u9fff-]+?)\s*(?:(?:&|and|èˆ‡|ã€)\s*([\w\s\u4e00-\u9fff-]+?))?\s*'
        r'(?:,?\s*et\s*al\.?)?\s*[,ï¼Œ]\s*(\d{4}[a-z]?)\s*[ï¼‰)]',
        re.UNICODE | re.IGNORECASE
    )
    for match in pattern_apa1.finditer(full_text):
        author1 = match.group(1).strip()
        author2 = match.group(2).strip() if match.group(2) else None
        year = match.group(3)[:4]
        # æ’é™¤ä½œè€…å…¨ç‚ºæ•¸å­—ï¼ˆå¦‚ 14ï¼‰
        if author1.isdigit():
            continue
        if is_valid_year(year):
            citation_id = f"{match.start()}-{match.end()}"
            if citation_id not in citation_ids:
                normalized = normalize_citation_for_matching(match.group(0))
                citations.append({
                    'author': author1,
                    'co_author': author2,
                    'year': year,
                    'original': match.group(0),
                    'normalized': normalized,
                    'position': match.start(),
                    'type': 'APA-parenthetical',
                    'format': 'APA'
                })
                citation_ids.add(citation_id)
    pattern_apa2 = re.compile(
        r'(?<![0-9])([\w\u4e00-\u9fff]+(?:\s+(?:et\s*al\.?|ç­‰))?)\s*[ï¼ˆ(]\s*(\d{4}[a-z]?)\s*[ï¼‰)]',
        re.UNICODE | re.IGNORECASE
    )
    for match in pattern_apa2.finditer(full_text):
        author = match.group(1).strip()
        year = match.group(2)[:4]
        # æ’é™¤ä½œè€…å…¨ç‚ºæ•¸å­—
        if author.isdigit():
            continue
        if is_valid_year(year):
            citation_id = f"{match.start()}-{match.end()}"
            if citation_id not in citation_ids:
                normalized = normalize_citation_for_matching(match.group(0))
                citations.append({
                    'author': author,
                    'co_author': None,
                    'year': year,
                    'original': match.group(0),
                    'normalized': normalized,
                    'position': match.start(),
                    'type': 'APA-narrative',
                    'format': 'APA'
                })
                citation_ids.add(citation_id)
    pattern_ieee = re.compile(r'[ã€\[]\s*(\d+)\s*[ã€‘\]]', re.UNICODE)
    for match in pattern_ieee.finditer(full_text):
        ref_number = match.group(1)
        citation_id = f"{match.start()}-{match.end()}"
        if citation_id not in citation_ids:
            normalized = normalize_citation_for_matching(match.group(0))
            citations.append({
                'author': None,
                'co_author': None,
                'year': None,
                'ref_number': ref_number,
                'original': match.group(0),
                'normalized': normalized,
                'position': match.start(),
                'type': 'IEEE-numeric',
                'format': 'IEEE'
            })
            citation_ids.add(citation_id)
    return citations


# ==================== 4. åƒè€ƒæ–‡ç»è§£æ ====================

def find_apa(ref_text):
    """
    æ”¹é€²ï¼šæ”¯æ´ (2007, October 11) / (2011, Jan. 14) / (n.d.)
    """
    ref_text = normalize_text(ref_text)

    apa_match = re.search(
        r'[ï¼ˆ(]\s*(\d{4}(?:[a-c])?|n\.d\.)\s*(?:,\s*(?:[A-Za-z]+\.?\s*\d{0,2}))?\s*[)ï¼‰]',
        ref_text, re.IGNORECASE
    )

    if not apa_match:
        return False

    year_str = apa_match.group(1)[:4]
    year_pos = apa_match.start(1)
    pre_context = ref_text[max(0, year_pos - 5):year_pos]
    if re.search(r'\d', pre_context):  # é¿å… 887(2020) èª¤åˆ¤
        return False

    return year_str.isdigit() or apa_match.group(1).lower() == "n.d."

def find_apalike(ref_text):
    valid_years = []
    for match in re.finditer(r'[,ï¼Œ.ã€‚]\s*(\d{4}[a-c]?)[.ã€‚ï¼Œ]', ref_text):
        year_str = match.group(1)
        year_pos = match.start(1)
        year_core = year_str[:4]
        if not is_valid_year(year_core): continue
        pre_context = ref_text[max(0, year_pos - 5):year_pos]
        if re.search(r'\d', pre_context): continue
        after_context = ref_text[match.end(1):match.end(1) + 5]
        if re.match(r'\.(\d{1,2}|[a-z0-9]{2,})', after_context, re.IGNORECASE): continue
        arxiv_pattern = re.compile(
            r'arxiv:\d{4}\.\d{5}[^a-zA-Z0-9]{0,3}\s*[,ï¼Œ]?\s*' + re.escape(year_str), re.IGNORECASE
        )
        if arxiv_pattern.search(ref_text) and arxiv_pattern.search(ref_text).start() < year_pos: continue
        valid_years.append((year_str, year_pos))
    for match in re.finditer(r'ï¼Œ\s*(\d{4}[a-c]?)\s*ï¼Œ\s*ã€‚', ref_text):
        year_str = match.group(1)
        year_pos = match.start(1)
        year_core = year_str[:4]
        if not is_valid_year(year_core): continue
        pre_context = ref_text[max(0, year_pos - 5):year_pos]
        if re.search(r'\d', pre_context): continue
        valid_years.append((year_str, year_pos))
    return valid_years

def is_reference_head(para):
    return bool(find_apa(para) or re.match(r"^\[\d+\]", para) or find_apalike(para))

def find_apa_matches(ref_text):
    APA_PATTERN = r'[ï¼ˆ(](\d{4}[a-c]?|n\.d\.)\s*(?:,\s*[A-Za-z]+\s*\d{1,2})?\s*[ï¼‰)]?[ã€‚\.]?'
    matches = []
    for m in re.finditer(APA_PATTERN, ref_text, re.IGNORECASE):
        year_str = m.group(1)[:4]
        year_pos = m.start(1)
        pre_context = ref_text[max(0, year_pos - 5):year_pos]
        if re.search(r'\d', pre_context): continue
        if year_str.isdigit() and is_valid_year(year_str):
            matches.append(m)
        elif m.group(1).lower() == "n.d.":
            matches.append(m)
    return matches

def find_apalike_matches(ref_text):
    matches = []
    pattern1 = r'[,ï¼Œ.ã€‚]\s*(\d{4}[a-c]?)[.ã€‚ï¼Œ]'
    for m in re.finditer(pattern1, ref_text):
        year_str = m.group(1)
        year_pos = m.start(1)
        year_core = year_str[:4]
        if not is_valid_year(year_core): continue
        pre_context = ref_text[max(0, year_pos - 5):year_pos]
        after_context = ref_text[m.end(1):m.end(1) + 5]
        if re.search(r'\d', pre_context): continue
        if re.match(r'\.(\d{1,2}|[a-z0-9]{2,})', after_context, re.IGNORECASE): continue
        arxiv_pattern = re.compile(
            r'arxiv:\d{4}\.\d{5}[^a-zA-Z0-9]{0,3}\s*[,ï¼Œ]?\s*' + re.escape(year_str), re.IGNORECASE
        )
        if arxiv_pattern.search(ref_text) and arxiv_pattern.search(ref_text).start() < year_pos: continue
        matches.append(m)
    pattern2 = r'ï¼Œ\s*(\d{4}[a-c]?)\s*ï¼Œ\s*ã€‚'
    for m in re.finditer(pattern2, ref_text):
        year_str = m.group(1)
        year_pos = m.start(1)
        year_core = year_str[:4]
        pre_context = ref_text[max(0, year_pos - 5):year_pos]
        if re.search(r'\d', pre_context): continue
        if is_valid_year(year_core):
            matches.append(m)
    return matches

def split_multiple_apa_in_paragraph(paragraph):
    apa_matches = find_apa_matches(paragraph)
    apalike_matches = find_apalike_matches(paragraph)
    all_matches = apa_matches + apalike_matches
    all_matches.sort(key=lambda m: m.start())
    if len(all_matches) < 2:
        return [paragraph]
    split_indices = []
    for match in all_matches[1:]:
        cut_index = max(0, match.start() - 5)
        split_indices.append(cut_index)
    segments = []
    start = 0
    for idx in split_indices:
        segments.append(paragraph[start:idx].strip())
        start = idx
    segments.append(paragraph[start:].strip())
    return [s for s in segments if s]

def merge_references_by_heads(paragraphs):
    merged = []
    for para in paragraphs:
        apa_count = 1 if find_apa(para) else 0
        apalike_count = len(find_apalike(para))
        if apa_count >= 2 or apalike_count >= 2:
            sub_refs = split_multiple_apa_in_paragraph(para)
            merged.extend([s.strip() for s in sub_refs if s.strip()])
        else:
            if is_reference_head(para):
                merged.append(para.strip())
            else:
                if merged:
                    merged[-1] += " " + para.strip()
                else:
                    merged.append(para.strip())
    return merged

def detect_reference_format(ref_text):
    """åµæ¸¬åƒè€ƒæ–‡ç»æ ¼å¼"""
    if re.match(r'^\s*[ã€\[]\s*\d+\s*[ã€‘\]]\s*', ref_text):
        return 'IEEE'
    
    if find_apa(ref_text):
        return 'APA'
    
    if find_apalike(ref_text):
        return 'APA_LIKE'
    
    return 'Unknown'


# ==================== ä¿®æ­£ç‰ˆï¼šIEEE æ–‡ç»è³‡è¨Šæ“·å– ====================

def extract_ieee_reference_info_fixed(ref_text):
    """ä¿®æ­£ç‰ˆ IEEE æ ¼å¼æ“·å–ï¼ˆä¿®å¾©å¤šä½œè€…å•é¡Œï¼‰"""
    
    number_match = re.match(r'^\s*[\[ã€]\s*(\d+)\s*[\]ã€‘]\s*', ref_text)
    if not number_match:
        return None
    
    ref_number = number_match.group(1)
    rest_text = ref_text[number_match.end():].strip()
    
    authors = "Unknown"
    title = None
    year = "Unknown"
    
    # æ­¥é©Ÿ 1ï¼šå„ªå…ˆæ‰¾å¼•è™Ÿä¸­çš„æ¨™é¡Œ
    quote_patterns = [
        (r'"', r'"'),
        (r'â€œ', r'â€'),
        (r'ã€Œ', r'ã€'),
        (r'\'', r'\''),
        (r'â€œ', r'â€œ'),
        (r'â€', r'â€'),
    ]
    
    title_found = False
    
    for open_q, close_q in quote_patterns:
        pattern = re.escape(open_q) + r'(.+?)' + re.escape(close_q)
        match = re.search(pattern, rest_text)
        
        if match:
            title = match.group(1).strip()
            title = re.sub(r'[,ï¼Œ.ã€‚;ï¼›:ï¼š]*$', '', title).strip()
            
            # å¼•è™Ÿå‰çš„æ‰€æœ‰å…§å®¹éƒ½æ˜¯ä½œè€…ï¼ˆåŒ…å«å¤šä½œè€…ï¼‰
            before_title = rest_text[:match.start()].strip()
            before_title = before_title.rstrip(',ï¼Œ. ')
            
            # ç§»é™¤å¯èƒ½çš„ "and" çµå°¾
            before_title = re.sub(r'\s+and\s*$', '', before_title, flags=re.IGNORECASE)
            # ç§»é™¤ et al. çµå°¾
            before_title = re.sub(r',?\s*et\s+al\.?$', '', before_title, flags=re.IGNORECASE)
            
            if before_title:
                # æ¸…ç†é–‹é ­çš„ç·¨è™Ÿæ®˜ç•™
                before_title = re.sub(r'^\[\d+\]\s*', '', before_title)
                
                # å®Œæ•´ä¿ç•™æ‰€æœ‰ä½œè€…ï¼ˆç”¨é€—è™Ÿåˆ†éš”çš„å¤šä½œè€…ï¼‰
                if re.search(r'[a-zA-Z\u4e00-\u9fff]', before_title) and len(before_title) > 1:
                    authors = before_title  # ä¿ç•™å®Œæ•´å¤šä½œè€…å­—ä¸²
            
            title_found = True
            break
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°å¼•è™Ÿæ¨™é¡Œï¼Œç”¨å‚™é¸æ–¹æ¡ˆ
    if not title_found:
        # å˜—è©¦ç”¨ "and" åˆ¤æ–·ä½œè€…å€æ®µçµå°¾
        and_match = re.search(r'\band\b', rest_text, re.IGNORECASE)
        
        if and_match:
            after_and = rest_text[and_match.end():].strip()
            next_comma = after_and.find(',')
            
            if next_comma > 0:
                # å¾é–‹é ­åˆ° "and" å¾Œç¬¬ä¸€å€‹é€—è™Ÿç‚ºä½œè€…
                authors_section = rest_text[:and_match.end() + next_comma].strip()
                authors_section = authors_section.rstrip(',ï¼Œ. ')
                
                # å®Œæ•´ä¿ç•™ä½œè€…å€æ®µ
                if authors_section and re.search(r'[a-zA-Z]', authors_section):
                    authors = authors_section
                
                # é€—è™Ÿå¾Œçš„å…§å®¹ç‚ºæ¨™é¡Œå€™é¸
                remaining = rest_text[and_match.end() + next_comma:].strip()
                remaining = remaining.lstrip(',ï¼Œ. ')
                
                title_match = re.match(r'^([^,ï¼Œ.ã€‚]+)', remaining)
                if title_match:
                    potential_title = title_match.group(1).strip()
                    if len(potential_title) > 10:
                        title = potential_title
        else:
            # æ²’æœ‰ "and"ï¼Œå˜—è©¦ç”¨ç¬¬ä¸€å€‹é€—è™Ÿåˆ†éš”
            parts = rest_text.split(',', 2)
            
            if len(parts) >= 2:
                potential_author = parts[0].strip()
                if potential_author and re.search(r'[a-zA-Z]', potential_author):
                    authors = potential_author
                
                potential_title = parts[1].strip()
                if len(potential_title) > 10:
                    title = potential_title
    
    # æå–å¹´ä»½
    year_matches = re.findall(r'\b(19\d{2}|20\d{2})\b', rest_text)
    if year_matches:
        year = year_matches[-1]
    
    return {
        'ref_number': ref_number,
        'authors': authors,
        'title': title if title else "Unknown",
        'year': year
    }

def extract_ieee_reference_full(ref_text):
    """
    å®Œæ•´è§£æ IEEE æ ¼å¼åƒè€ƒæ–‡ç»
    è¿”å›ï¼šæ ¼å¼ã€æ–‡ç»é¡å‹ã€æ‰€æœ‰æ¬„ä½
    """
    
    # åŸºæœ¬æ¬„ä½åˆå§‹åŒ–
    result = {
        'format': 'IEEE',
        'ref_number': None,
        'source_type': 'Unknown',
        'authors': None,
        'title': None,
        'journal_name': None,
        'conference_name': None,
        'book_title': None,
        'volume': None,
        'issue': None,
        'pages': None,
        'year': None,
        'month': None,
        'publisher': None,
        'location': None,
        'edition': None,
        'url': None,
        'access_date': None,
        'doi': None,
        'report_number': None,
        'patent_number': None,
        'original': ref_text
    }
    
    # æå–ç·¨è™Ÿ
    number_match = re.match(r'^\s*[\[ã€]\s*(\d+)\s*[\]ã€‘]\s*', ref_text)
    if not number_match:
        return result
    
    result['ref_number'] = number_match.group(1)
    rest_text = ref_text[number_match.end():].strip()
    
    # === 1. æå–ä½œè€…å’Œæ¨™é¡Œï¼ˆä½¿ç”¨ä½ çš„å¼•è™Ÿåµæ¸¬é‚è¼¯ï¼‰ ===
    authors = "Unknown"
    title = None
    
    # å„ªå…ˆæ‰¾å¼•è™Ÿä¸­çš„æ¨™é¡Œï¼ˆä½œè€…èˆ‡æ¨™é¡Œåˆ†ç•Œé»ï¼‰
    quote_patterns = [
        (r'"', r'"'),
        (r'"', r'"'),
        (r'ã€Œ', r'ã€'),
        (r'â€œ', r'â€'),
        (r'â€œ', r'â€œ') ,
        (r'\'', r'\''),
        (r'â€', r'â€')
    ]
    
    title_found = False
    after_title = rest_text
    
    for open_q, close_q in quote_patterns:
        pattern = re.escape(open_q) + r'(.+?)' + re.escape(close_q)
        match = re.search(pattern, rest_text)
        
        if match:
            title = match.group(1).strip()
            title = re.sub(r'[,ï¼Œ.ã€‚;ï¼›:ï¼š]*$', '', title).strip()
            result['title'] = title
            
            # å¼•è™Ÿå‰çš„æ‰€æœ‰å…§å®¹éƒ½æ˜¯ä½œè€…ï¼ˆåŒ…å«å¤šä½œè€…ï¼‰
            before_title = rest_text[:match.start()].strip()
            before_title = before_title.rstrip(',ï¼Œ. ')
            
            # ç§»é™¤å¯èƒ½çš„ "and" çµå°¾
            before_title = re.sub(r'\s+and\s*$', '', before_title, flags=re.IGNORECASE)
            # ç§»é™¤ et al. çµå°¾
            before_title = re.sub(r',?\s*et\s+al\.?$', '', before_title, flags=re.IGNORECASE)
            
            if before_title:
                # æ¸…ç†é–‹é ­çš„ç·¨è™Ÿæ®˜ç•™
                before_title = re.sub(r'^\[\d+\]\s*', '', before_title)
                
                # å®Œæ•´ä¿ç•™æ‰€æœ‰ä½œè€…ï¼ˆç”¨é€—è™Ÿåˆ†éš”çš„å¤šä½œè€…ï¼‰
                if re.search(r'[a-zA-Z\u4e00-\u9fff]', before_title) and len(before_title) > 1:
                    authors = before_title
            
            result['authors'] = authors
            after_title = rest_text[match.end():].strip()
            title_found = True
            break
    
    # å¦‚æœæ²’æœ‰æ‰¾åˆ°å¼•è™Ÿæ¨™é¡Œï¼Œç”¨å‚™é¸æ–¹æ¡ˆ
    if not title_found:
        # å˜—è©¦ç”¨ "and" åˆ¤æ–·ä½œè€…å€æ®µçµå°¾
        and_match = re.search(r'\band\b', rest_text, re.IGNORECASE)
        
        if and_match:
            after_and = rest_text[and_match.end():].strip()
            next_comma = after_and.find(',')
            
            if next_comma > 0:
                # å¾é–‹é ­åˆ° "and" å¾Œç¬¬ä¸€å€‹é€—è™Ÿç‚ºä½œè€…
                authors_section = rest_text[:and_match.end() + next_comma].strip()
                authors_section = authors_section.rstrip(',ï¼Œ. ')
                
                # å®Œæ•´ä¿ç•™ä½œè€…å€æ®µ
                if authors_section and re.search(r'[a-zA-Z]', authors_section):
                    authors = authors_section
                    result['authors'] = authors
                
                # é€—è™Ÿå¾Œçš„å…§å®¹ç‚ºæ¨™é¡Œå€™é¸
                remaining = rest_text[and_match.end() + next_comma:].strip()
                remaining = remaining.lstrip(',ï¼Œ. ')
                
                title_match = re.match(r'^([^,ï¼Œ.ã€‚]+)', remaining)
                if title_match:
                    potential_title = title_match.group(1).strip()
                    if len(potential_title) > 10:
                        title = potential_title
                        result['title'] = title
                
                after_title = remaining
        else:
            # æ²’æœ‰ "and"ï¼Œå˜—è©¦ç”¨ç¬¬ä¸€å€‹é€—è™Ÿåˆ†éš”
            parts = rest_text.split(',', 2)
            
            if len(parts) >= 2:
                potential_author = parts[0].strip()
                if potential_author and re.search(r'[a-zA-Z]', potential_author):
                    authors = potential_author
                    result['authors'] = authors
                
                potential_title = parts[1].strip()
                if len(potential_title) > 10:
                    title = potential_title
                    result['title'] = title
                
                if len(parts) >= 3:
                    after_title = parts[2]
    
    # === 2. åˆ¤æ–·æ–‡ç»é¡å‹ ===
    if re.search(r'\bin\b.*(Proc\.|Proceedings|Conference|Symposium|Workshop)', after_title, re.IGNORECASE):
        result['source_type'] = 'Conference Paper'
        conf_match = re.search(r'\bin\s+(.+?)(?:,|\d{4})', after_title, re.IGNORECASE)
        if conf_match:
            result['conference_name'] = conf_match.group(1).strip()
    
    elif re.search(r'(vol\.|volume|no\.|number)', after_title, re.IGNORECASE):
        result['source_type'] = 'Journal Article'
        journal_match = re.search(r'^([^,]+)', after_title)
        if journal_match:
            result['journal_name'] = journal_match.group(1).strip()
    
    elif re.search(r'\[Online\]|Available:|https?://', after_title, re.IGNORECASE):
        result['source_type'] = 'Website/Online'

    elif re.search(r'\[Online\]|Available:|https?://|arxiv\.org', after_title, re.IGNORECASE):
        result['source_type'] = 'Website/Online'

    elif re.search(r'(Ph\.D\.|M\.S\.|thesis|dissertation)', after_title, re.IGNORECASE):
        result['source_type'] = 'Thesis/Dissertation'
    
    elif re.search(r'(Tech\. Rep\.|Technical Report)', after_title, re.IGNORECASE):
        result['source_type'] = 'Technical Report'
    
    elif re.search(r'Patent', after_title, re.IGNORECASE):
        result['source_type'] = 'Patent'
    
    elif re.search(r'(Ed\.|Eds\.|edition)', after_title, re.IGNORECASE):
        result['source_type'] = 'Book'
    
    # === 3. æå–é€šç”¨æ¬„ä½ ===

    # å·è™Ÿ
    vol_match = re.search(r'vol\.\s*(\d+)', after_title, re.IGNORECASE)
    if vol_match:
        result['volume'] = vol_match.group(1)

    # æœŸè™Ÿ
    issue_match = re.search(r'no\.\s*(\d+)', after_title, re.IGNORECASE)
    if issue_match:
        result['issue'] = issue_match.group(1)

    # é ç¢¼ï¼ˆæ”¹é€²ï¼šæ›´ç²¾ç¢ºçš„åŒ¹é…ï¼Œé¿å…æŠ“åˆ°æˆæ¬Šè³‡è¨Šä¸­çš„æ•¸å­—ï¼‰
    pages_match = re.search(r'pp\.\s*([\d]+\s*[â€“\-â€”]\s*[\d]+)', after_title, re.IGNORECASE)
    if pages_match:
        # æ¸…ç†é ç¢¼ä¸­çš„ç©ºæ ¼
        pages = pages_match.group(1)
        pages = re.sub(r'\s+', '', pages)  # ç§»é™¤ç©ºæ ¼
        pages = pages.replace('â€“', '-').replace('â€”', '-')  # çµ±ä¸€é€£å­—ç¬¦
        result['pages'] = pages

    # å¹´ä»½
    year_matches = re.findall(r'\b(19\d{2}|20\d{2})\b', after_title)
    if year_matches:
        result['year'] = year_matches[0]  # å–ç¬¬ä¸€å€‹å¹´ä»½ï¼ˆé¿å…æŠ“åˆ°ä¸‹è¼‰æ—¥æœŸï¼‰

    # æœˆä»½
    month_match = re.search(r'\b(Jan\.|Feb\.|Mar\.|Apr\.|May|Jun\.|Jul\.|Aug\.|Sep\.|Oct\.|Nov\.|Dec\.)\b', 
                        after_title, re.IGNORECASE)
    if month_match:
        result['month'] = month_match.group(1)

    # URLï¼ˆæ”¹é€²ï¼šæ”¯æ´ arXivã€GitHub ç­‰å„ç¨® URLï¼Œå«ç©ºæ ¼è™•ç†ï¼‰
    url = None

    # 1. å„ªå…ˆç›´æ¥æŠ“ Available: / Retrieved from å¾Œçš„ç¶²å€ï¼Œå…¨é•·ä¸”å…è¨±ç©ºç™½
    url_match = re.search(r'(?:Available:|Retrieved from)\s*(https?://[^\s,]+(?:\s+[^\s,]+)*)', after_title, re.IGNORECASE)
    if url_match:
        # åˆä½µæ‰€æœ‰æ›è¡Œèˆ‡ç©ºç™½ä½¿å…¶ç‚ºä¸€è¡Œ
        url = url_match.group(1).strip().replace(' ', '')

    # 2. å¦‚æœæ²’æŠ“åˆ°ï¼Œå†æŠ“æ‰€æœ‰ http é–‹é ­åˆ°é‡åˆ°ç©ºç™½/é€—è™Ÿ/å¥è™Ÿ/çµå°¾
    if not url:
        generic_url_match = re.search(r'(https?://[^\s,.;]+)', after_title)
        if generic_url_match:
            url = generic_url_match.group(1).strip()

    # 3. æœ€å¾Œå¯«å…¥ result
    if url:
        result['url'] = url

    # å­˜å–æ—¥æœŸï¼ˆæ”¹é€²ï¼šæ›´ç²¾ç¢ºåŒ¹é…ï¼‰
    access_match = re.search(
        r'(?:accessed|retrieved|downloaded)\s+(?:on\s+)?([A-Za-z]+\.?\s+\d{1,2},?\s*\d{4})', 
        after_title, 
        re.IGNORECASE
    )
    if access_match:
        result['access_date'] = access_match.group(1)

    # DOIï¼ˆæ–°å¢ï¼šæ”¯æ´å¤šç¨® DOI æ ¼å¼ï¼‰
    doi_patterns = [
        r'doi:\s*(10\.\d{4,}/[^\s,]+)',  # æ¨™æº–æ ¼å¼ï¼šdoi: 10.xxxx/xxxxx
        r'https?://(?:dx\.)?doi\.org/(10\.\d{4,}/[^\s,]+)',  # URL æ ¼å¼ï¼šhttps://doi.org/10.xxxx/xxxxx
        r'DOI:\s*(10\.\d{4,}/[^\s,]+)',  # å¤§å¯« DOI
    ]

    for pattern in doi_patterns:
        doi_match = re.search(pattern, after_title, re.IGNORECASE)
        if doi_match:
            result['doi'] = doi_match.group(1).rstrip('.,;')
            break

    # å‡ºç‰ˆç¤¾èˆ‡åœ°é»
    publisher_match = re.search(
        r'([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*),\s+([A-Z]{2,}(?:,\s+[A-Z]{2,})?)\s*:\s*([^,]+)', 
        after_title
    )
    if publisher_match:
        result['location'] = publisher_match.group(1) + ', ' + publisher_match.group(2)
        result['publisher'] = publisher_match.group(3)

    # ç‰ˆæœ¬
    edition_match = re.search(r'(\d+(?:st|nd|rd|th)\s+ed\.)', after_title, re.IGNORECASE)
    if edition_match:
        result['edition'] = edition_match.group(1)

    # å ±å‘Šç·¨è™Ÿ
    report_match = re.search(r'(Tech\.\s+Rep\.|Rep\.)\s+([\w\-]+)', after_title, re.IGNORECASE)
    if report_match:
        result['report_number'] = report_match.group(2)

    # å°ˆåˆ©è™Ÿ
    patent_match = re.search(r'(U\.S\.|US)\s+Patent\s+([\d,]+)', after_title, re.IGNORECASE)
    if patent_match:
        result['patent_number'] = patent_match.group(2)
    
    return result



def extract_apa_reference_info_fixed(ref_text):
    """
    APA æ ¼å¼æ“·å–ï¼ˆä¿®æ­£å¤šä½œè€…å•é¡Œ + æ”¯æ´å®Œæ•´æ—¥æœŸ + æ”¹é€²æ¨™é¡Œæ“·å–ï¼‰
    """
    
    # æ‰¾å¹´ä»½ï¼ˆå¿…é ˆæœ‰æ‹¬è™Ÿ,æ”¯æ´å®Œæ•´æ—¥æœŸæ ¼å¼ï¼‰
    year_match = re.search(
        r'[ï¼ˆ(]\s*(\d{4}[a-z]?|n\.d\.)\s*(?:,\s*([A-Za-z]+\.?\s*\d{0,2}))?\s*[ï¼‰)]',
        ref_text, 
        re.IGNORECASE
    )
    
    if not year_match:
        return {
            'author': 'Unknown',
            'year': 'Unknown',
            'date': None,
            'title': None
        }
    
    year_text = year_match.group(1)
    year = year_text[:4] if year_text.lower() != 'n.d.' else 'n.d.'
    
    # æå–å®Œæ•´æ—¥æœŸï¼ˆå¦‚æœæœ‰æœˆä»½æ—¥æœŸï¼‰
    date_str = year_match.group(2) if year_match.group(2) else None
    
    # æå–ä½œè€…ï¼ˆå¹´ä»½å‰çš„å…§å®¹ï¼‰
    before_year = ref_text[:year_match.start()].strip()
    author = "Unknown"
    
    if before_year:
        # ç§»é™¤æœ«å°¾çš„æ¨™é»å’Œç©ºæ ¼
        before_year = before_year.rstrip(',ï¼Œ. ')
        
        # æª¢æŸ¥é•·åº¦å’Œå…§å®¹
        if 2 <= len(before_year) <= 300:
            # æ’é™¤ç„¡æ•ˆçš„ä½œè€…å
            invalid_patterns = [
                r'^\d+$',  # ç´”æ•¸å­—
                r'^[ï¼Œ,\.ã€‚]+$',  # ç´”æ¨™é»
            ]
            
            is_valid = True
            for pattern in invalid_patterns:
                if re.match(pattern, before_year, re.IGNORECASE):
                    is_valid = False
                    break
            
            # ç›´æ¥ä½¿ç”¨æ•´å€‹ before_yearï¼ˆä¿ç•™å¤šä½œè€…ï¼‰
            if is_valid and re.search(r'[a-zA-Z\u4e00-\u9fff]', before_year):
                author = before_year
    
    # æå–æ¨™é¡Œï¼ˆå¹´ä»½å¾Œçš„å…§å®¹ï¼‰
    after_year = ref_text[year_match.end():].strip()
    title = None
    
    if after_year:
        # ç§»é™¤é–‹é ­çš„æ¨™é»ç¬¦è™Ÿå’Œç©ºæ ¼
        after_year = re.sub(r'^[\s.,ï¼Œã€‚)\]ã€‘]+', '', after_year)
        
        if after_year:
            # å…ˆè™•ç†ç‰¹æ®Šæƒ…æ³ï¼šæ–œé«”æ¨™è¨˜
            after_year = re.sub(r'</?i>', '', after_year)
            
            # 1. å…ˆæ‰¾æ˜¯å¦æœ‰æ˜ç¢ºçš„æ¨™é¡ŒçµæŸæ¨™è¨˜
            title_end_markers = [
                r'Retrieved from',
                r'Available from',
                r'Available at',
                r'\[Electronic version\]',
                r'DOI:',
                r'doi:',
                r'https?://',
            ]
            
            title_end_pos = len(after_year)
            for marker in title_end_markers:
                match = re.search(marker, after_year, re.IGNORECASE)
                if match and match.start() < title_end_pos:
                    title_end_pos = match.start()
            
            # å–æ¨™é¡ŒçµæŸæ¨™è¨˜å‰çš„å…§å®¹
            title_candidate = after_year[:title_end_pos].strip()
            
            # 2. æ¸…ç†æ¨™é¡Œæœ«å°¾
            # ç§»é™¤æœ«å°¾çš„æœŸåˆŠè³‡è¨Šæ¨™è¨˜
            title_candidate = re.sub(
                r'\s*[\.,]\s*$',
                '',
                title_candidate
            )
            
            # ç§»é™¤å¯èƒ½çš„æœŸåˆŠåç¨±ï¼ˆæ–œé«”æ¨™è¨˜å¾Œçš„å…§å®¹ï¼‰
            # ä¾‹å¦‚: "Title. Journal Name" -> "Title"
            if '.' in title_candidate:
                parts = title_candidate.split('.')
                # å¦‚æœç¬¬ä¸€éƒ¨åˆ†å¤ é•·,å°±ç”¨ç¬¬ä¸€éƒ¨åˆ†
                if len(parts[0].strip()) >= 10:
                    title_candidate = parts[0].strip()
            
            # 3. é©—è­‰æ¨™é¡Œ
            if len(title_candidate) >= 5:
                if not re.match(r'^(Retrieved|Available|DOI|doi|https?|www)', title_candidate, re.IGNORECASE):
                    if not (title_candidate.isupper() and len(title_candidate) < 20):
                        title = title_candidate
    
    return {
        'author': author,
        'year': year,
        'date': date_str,
        'title': title
    }

def extract_apalike_reference_info_fixed(ref_text):
    """ä¿®æ­£ç‰ˆ APA_LIKE æ ¼å¼æ“·å–"""
    
    years = find_apalike(ref_text)
    
    if not years:
        return {
            'author': 'Unknown',
            'year': 'Unknown',
            'title': None,
            'format': 'APA_LIKE'
        }
    
    year_str, year_pos = years[-1]
    year = year_str[:4]
    
    before_year = ref_text[:year_pos].strip()
    
    author = "Unknown"
    title = None
    
    parts = re.split(r'[,ï¼Œ.ã€‚]', before_year)
    parts = [p.strip() for p in parts if p.strip()]
    
    if parts:
        if parts[0] and re.search(r'[a-zA-Z\u4e00-\u9fff]', parts[0]):
            author = parts[0]
        
        if len(parts) > 1:
            potential_title = parts[1]
            if potential_title and len(potential_title) > 5:
                title = potential_title
    
    return {
        'author': author,
        'year': year,
        'title': title,
        'format': 'APA_LIKE'
    }


def merge_ieee_references(ref_paragraphs):
    """å¢å¼·ç‰ˆ IEEE æ®µè½åˆä½µ"""
    merged = []
    current_ref = ""
    
    for para in ref_paragraphs:
        para = para.strip()
        if not para:
            continue
        
        if re.match(r'^\s*[ã€\[]\s*\d+\s*[ã€‘\]]\s*', para):
            if current_ref:
                merged.append(current_ref.strip())
            current_ref = para
            continue
        
        if len(para) < 20:
            current_ref += " " + para
            continue
        
        if re.match(r'^[a-z]', para):
            current_ref += " " + para
            continue
        
        if re.match(r'^[,ï¼Œ.ã€‚;ï¼›:"\'\-]', para):
            current_ref += " " + para
            continue
        
        if any(keyword in para for keyword in ['http', 'doi:', 'DOI:', '[Online]', 'Available', '.pdf', '.doi']):
            current_ref += " " + para
            continue
        
        if current_ref and not re.search(r'[.ã€‚!ï¼?ï¼Ÿ]$', current_ref.strip()):
            current_ref += " " + para
            continue
        
        if re.match(r'^[A-Z][a-z]+(?:\s+and\s+|\s*,\s*)', para):
            current_ref += " " + para
            continue
        
        if current_ref:
            current_ref += " " + para
        else:
            current_ref = para
    
    if current_ref:
        merged.append(current_ref.strip())
    
    return merged


def extract_reference_info(ref_paragraphs):
    """å¾åƒè€ƒæ–‡ç»æ®µè½ä¸­æå–åŸºæœ¬è³‡è¨Šï¼ˆä½¿ç”¨ä¿®æ­£ç‰ˆï¼‰"""
    if not ref_paragraphs:
        return []
    
    first_ref = normalize_text(ref_paragraphs[0])
    is_ieee_format = re.match(r'^\s*[ã€\[]\s*\d+\s*[ã€‘\]]\s*', first_ref)
    
    if is_ieee_format:
        ref_paragraphs = merge_ieee_references(ref_paragraphs)
    
    ref_list = []
    
    for ref_text in ref_paragraphs:
        format_type = detect_reference_format(ref_text)
        
        if format_type == 'IEEE':
            ieee_info = extract_ieee_reference_info_fixed(ref_text)
            
            if ieee_info:
                ref_list.append({
                    'author': ieee_info['authors'],
                    'year': ieee_info['year'],
                    'date': None,
                    'ref_number': ieee_info['ref_number'],
                    'title': ieee_info['title'],
                    'format': 'IEEE',
                    'original': ref_text
                })
            else:
                ref_list.append({
                    'author': 'Parse Error',
                    'year': 'Unknown',
                    'date': None,
                    'ref_number': 'Unknown',
                    'title': None,
                    'format': 'IEEE',
                    'original': ref_text
                })
        
        elif format_type == 'APA':
            apa_info = extract_apa_reference_info_fixed(ref_text)
            ref_list.append({
                'author': apa_info['author'],
                'year': apa_info['year'],
                'date': apa_info.get('date'), 
                'ref_number': None,
                'title': apa_info['title'],
                'format': 'APA',
                'original': ref_text
            })
        
        elif format_type == 'APA_LIKE':
            apalike_info = extract_apalike_reference_info_fixed(ref_text)
            ref_list.append({
                'author': apalike_info['author'],
                'year': apalike_info['year'],
                'date': None,
                'ref_number': None,
                'title': apalike_info['title'],
                'format': 'APA_LIKE',
                'original': ref_text
            })
        
        else:
            ref_list.append({
                'author': 'Unknown Format',
                'year': 'Unknown',
                'date': None,
                'ref_number': None,
                'title': None,
                'format': 'Unknown',
                'original': ref_text
            })
    
    return ref_list

# ==================== 5. JSON æš«å­˜åŠŸèƒ½ ====================

def init_session_state():
    """session_state æ˜¯ Streamlit çš„è¨˜æ†¶é«”æš«å­˜æ©Ÿåˆ¶ï¼Œé é¢é‡æ–°æ•´ç†å¾Œè³‡æ–™ä¸æœƒæ¶ˆå¤±"""

    #å„²å­˜å…§æ–‡ä¸­çš„å¼•ç”¨
    if 'in_text_citations' not in st.session_state: 
        st.session_state.in_text_citations = []
    # å„²å­˜åƒè€ƒæ–‡ç»åˆ—è¡¨
    if 'reference_list' not in st.session_state:
        st.session_state.reference_list = []
    # å„²å­˜å·²é€é API é©—è­‰éçš„æ­£ç¢ºæ–‡ç»
    if 'verified_references' not in st.session_state:
        st.session_state.verified_references = []

def save_to_session(in_text_citations, reference_list):
    """å°‡è³‡æ–™å„²å­˜åˆ° session state"""
    st.session_state.in_text_citations = in_text_citations
    st.session_state.reference_list = reference_list

def export_to_json():
    """åŒ¯å‡ºç‚º JSON æ ¼å¼: å°‡ä¸‰å€‹æ¸…å–®æ‰“åŒ…æˆä¸€å€‹ JSON ç‰©ä»¶"""
    data = {
        "export_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "in_text_citations": st.session_state.in_text_citations,
        "reference_list": st.session_state.reference_list,
        "verified_references": st.session_state.verified_references
    }

    # ensure_ascii=Falseï¼šä¿ç•™ä¸­æ–‡å­—å…ƒ, indent=2ï¼šæ ¼å¼åŒ–è¼¸å‡ºï¼Œæ–¹ä¾¿é–±è®€
    return json.dumps(data, ensure_ascii=False, indent=2)

def import_from_json(json_str):
    """å¾ JSON åŒ¯å…¥è³‡æ–™"""
    try:
        data = json.loads(json_str)
        st.session_state.in_text_citations = data.get("in_text_citations", [])
        st.session_state.reference_list = data.get("reference_list", [])
        st.session_state.verified_references = data.get("verified_references", [])
        return True, "è³‡æ–™åŒ¯å…¥æˆåŠŸï¼"
    except Exception as e:
        return False, f"åŒ¯å…¥å¤±æ•—ï¼š{str(e)}"

def add_verified_reference(ref_data):
    """æ–°å¢å·²é©—è­‰çš„æ–‡ç»è³‡æ–™"""
    if 'verified_references' not in st.session_state:
        st.session_state.verified_references = []
    st.session_state.verified_references.append(ref_data)

# ==================== Streamlit UI ====================

st.set_page_config(page_title="æ–‡ç»æª¢æŸ¥ç³»çµ±", layout="wide")
# åˆå§‹åŒ– session state
init_session_state()

st.title("ğŸ“š å­¸è¡“æ–‡ç»å¼•ç”¨æª¢æŸ¥ç³»çµ±")

st.markdown("""
### âœ¨ åŠŸèƒ½ç‰¹è‰²
1. âœ… **åƒè€ƒæ–‡ç»æª¢æŸ¥**ï¼šæª¢æŸ¥æ–‡ç»æ˜¯å¦éƒ½è¢«å¼•ç”¨
2. âœ… **å…§æ–‡å¼•ç”¨æª¢æŸ¥**ï¼šæª¢æŸ¥å…§æ–‡ä¸­çš„å¼•ç”¨æ˜¯å¦éƒ½å°æ‡‰åƒè€ƒæ–‡ç»
3. âœ… **æ–‡ç»çœŸå¯¦æ€§é©—è­‰**ï¼šé€é DOI/ISBN/ç·šä¸Šè³‡æ–™åº«é©—è­‰
4. âœ… **æ ¼å¼ä¸€è‡´æ€§æª¢æŸ¥**ï¼šæª¢æŸ¥æ ¼å¼æ˜¯å¦ç¬¦åˆå­¸è¡“è¦ç¯„
5. âœ… **æ ¼å¼è½‰æ›å·¥å…·**ï¼šæä¾› APA/IEEE ç­‰æ ¼å¼ç›¸äº’è½‰æ›
6. âœ… **ç”Ÿæˆæª¢æŸ¥å ±è¡¨**ï¼šè¼¸å‡ºå®Œæ•´å ±å‘Š            
""")

st.markdown("---")

# ==================== JSON è³‡æ–™ç®¡ç†å€ ====================
with st.sidebar:
    st.header("ğŸ’¾ è³‡æ–™ç®¡ç†")
    
    # é¡¯ç¤ºç•¶å‰æš«å­˜ç‹€æ…‹
    st.subheader("ğŸ“Š ç•¶å‰æš«å­˜ç‹€æ…‹")
    st.metric("å…§æ–‡å¼•ç”¨æ•¸é‡", len(st.session_state.in_text_citations))
    st.metric("åƒè€ƒæ–‡ç»æ•¸é‡", len(st.session_state.reference_list))
    st.metric("å·²é©—è­‰æ–‡ç»", len(st.session_state.verified_references))
    
    st.markdown("---")
    
    # åŒ¯å‡ºåŠŸèƒ½
    st.subheader("ğŸ“¤ åŒ¯å‡ºè³‡æ–™")
    if st.button("åŒ¯å‡ºç‚º JSON", use_container_width=True):
        json_data = export_to_json()
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ JSON æª”æ¡ˆ",
            data=json_data,
            file_name=f"citation_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            use_container_width=True
        )
    
    # åŒ¯å…¥åŠŸèƒ½
    st.subheader("ğŸ“¥ åŒ¯å…¥è³‡æ–™")
    uploaded_json = st.file_uploader("ä¸Šå‚³ JSON æª”æ¡ˆ", type=['json'])
    if uploaded_json:
        json_str = uploaded_json.read().decode('utf-8')
        success, message = import_from_json(json_str)
        if success:
            st.session_state.json_imported = True
            st.success(message)
        else:
            st.error(message)
            
    # æ¸…é™¤åŒ¯å…¥æ¨™è¨˜ï¼ˆç•¶æª”æ¡ˆè¢«ç§»é™¤æ™‚ï¼‰
    if not uploaded_json and 'json_imported' in st.session_state:
        del st.session_state.json_imported
    
    # æ¸…ç©ºè³‡æ–™
    st.markdown("---")
    st.subheader("ğŸ—‘ï¸ æ¸…ç©ºè³‡æ–™")
    if st.button("æ¸…ç©ºæ‰€æœ‰æš«å­˜", type="secondary", use_container_width=True):
        st.session_state.in_text_citations = []
        st.session_state.reference_list = []
        st.session_state.verified_references = []
        st.success("å·²æ¸…ç©ºæ‰€æœ‰æš«å­˜è³‡æ–™")
        st.rerun() #é‡æ–°è¼‰å…¥é é¢ï¼Œæ›´æ–°å´é‚Šæ¬„çš„æ•¸é‡é¡¯ç¤º

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ Word æˆ– PDF æª”æ¡ˆ", type=["docx", "pdf"])

# å¦‚æœæœ‰åŒ¯å…¥çš„è³‡æ–™ä½†æ²’æœ‰ä¸Šå‚³æª”æ¡ˆï¼Œé¡¯ç¤ºåŒ¯å…¥çš„è³‡æ–™
if not uploaded_file and (st.session_state.in_text_citations or st.session_state.reference_list):
    st.info("ğŸ“¥ é¡¯ç¤ºå·²åŒ¯å…¥çš„è³‡æ–™")

elif uploaded_file:
    file_ext = uploaded_file.name.split(".")[-1].lower()
    
    st.subheader(f"ğŸ“„ è™•ç†æª”æ¡ˆï¼š{uploaded_file.name}")
    
    with st.spinner("æ­£åœ¨è®€å–æª”æ¡ˆ..."):
        if file_ext == "docx":
            all_paragraphs = extract_paragraphs_from_docx(uploaded_file)
        elif file_ext == "pdf":
            all_paragraphs = extract_paragraphs_from_pdf(uploaded_file)
        else:
            st.error("ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼")
            st.stop()
    
    st.success(f"âœ… æˆåŠŸè®€å– {len(all_paragraphs)} å€‹æ®µè½")
    
    st.markdown("---")
    
    content_paras, ref_paras, ref_start_idx, ref_keyword = classify_document_sections(all_paragraphs)
    
    st.markdown("---")
    
    st.subheader("ğŸ” å…§æ–‡å¼•ç”¨åˆ†æï¼ˆAPA + IEEEï¼‰")
    
    if content_paras:
        in_text_citations = extract_in_text_citations(content_paras)

        # å°‡å…§æ–‡å¼•ç”¨è½‰æ›ç‚ºå¯åºåˆ—åŒ–æ ¼å¼ä¸¦å„²å­˜ (ç¢ºä¿å¯ä»¥è½‰ç‚º JSON)
        serializable_citations = []
        for cite in in_text_citations:
            cite_dict = {
                'author': cite.get('author'),
                'co_author': cite.get('co_author'),
                'year': cite.get('year'),
                'ref_number': cite.get('ref_number'),
                'original': cite.get('original'),
                'normalized': cite.get('normalized'),
                'position': cite.get('position'),
                'type': cite.get('type'),
                'format': cite.get('format')
            }
            serializable_citations.append(cite_dict)
        
        # å„²å­˜åˆ° session state
        st.session_state.in_text_citations = serializable_citations
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                border-radius: 12px;
                padding: 24px;
                text-align: center;
                color: white;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            ">
                <div style="font-size: 20px; opacity: 0.9; margin-bottom: 8px;">å…§æ–‡å¼•ç”¨ç¸½æ•¸</div>
                <div style="font-size: 36px; font-weight: bold;">{len(in_text_citations)}</div>
            </div>
            """, unsafe_allow_html=True)
        
        apa_count = sum(1 for c in in_text_citations if c['format'] == 'APA')
        with col2:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
                border-radius: 12px;
                padding: 24px;
                text-align: center;
                color: white;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            ">
                <div style="font-size: 20px; opacity: 0.9; margin-bottom: 8px;">APA æ ¼å¼å¼•ç”¨</div>
                <div style="font-size: 36px; font-weight: bold;">{apa_count}</div>
            </div>
            """, unsafe_allow_html=True)
        
        ieee_count = sum(1 for c in in_text_citations if c['format'] == 'IEEE')
        with col3:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #0066cc 0%, #0080ff 100%);
                border-radius: 12px;
                padding: 24px;
                text-align: center;
                color: white;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            ">
                <div style="font-size: 20px; opacity: 0.9; margin-bottom: 8px;">IEEE æ ¼å¼å¼•ç”¨</div>
                <div style="font-size: 36px; font-weight: bold;">{ieee_count}</div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        if in_text_citations:
            with st.expander("ğŸ“‹ æŸ¥çœ‹æ‰€æœ‰å…§æ–‡å¼•ç”¨"):
                for i, cite in enumerate(in_text_citations, 1):
                    if cite['format'] == 'APA':
                        co_author_text = f" & {cite['co_author']}" if cite['co_author'] else ""
                        st.markdown(
                            f"{i}. `{cite['original']}` â€” "
                            f"**[{cite['format']}]** "
                            f"ä½œè€…ï¼š**{cite['author']}{co_author_text}** | "
                            f"å¹´ä»½ï¼š**{cite['year']}** | "
                            f"é¡å‹ï¼š{cite['type']}"
                        )
                    else:
                        st.markdown(
                            f"{i}. `{cite['original']}` â€” "
                            f"**[{cite['format']}]** "
                            f"åƒè€ƒç·¨è™Ÿï¼š**{cite['ref_number']}**"
                        )
        else:
            st.info("æœªæ‰¾åˆ°ä»»ä½•å…§æ–‡å¼•ç”¨")
    else:
        st.warning("ç„¡å…§æ–‡æ®µè½å¯ä¾›åˆ†æ")
    
    st.markdown("---")
    
    st.subheader("ğŸ“– åƒè€ƒæ–‡ç»å®Œæ•´è§£æ")
    
    if ref_paras:
        apa_refs_merged = merge_references_by_heads(ref_paras)
        ref_info = extract_reference_info(apa_refs_merged)

        # å°‡åƒè€ƒæ–‡ç»è½‰æ›ç‚ºå¯åºåˆ—åŒ–æ ¼å¼ä¸¦å„²å­˜
        serializable_refs = []
        for ref in ref_info:
            ref_dict = {
                'author': ref.get('author'),
                'year': ref.get('year'),
                'date': ref.get('date'),
                'ref_number': ref.get('ref_number'),
                'title': ref.get('title'),
                'format': ref.get('format'),
                'original': ref.get('original')
            }
            serializable_refs.append(ref_dict)
        
        # å„²å­˜åˆ° session state
        st.session_state.reference_list = serializable_refs

        # APAä¸»éµ: ç¬¬ä¸€ä½œè€…+å¹´ä»½
        apa_citation_pairs = set(
            (c['author'].strip().lower(), c['year'])
            for c in in_text_citations
            if c['format']=="APA" and c['author'] and c['year']
        )
        ref_pairs = set()
        for ref in apa_refs_merged:
            info = extract_apa_reference_info_fixed(ref)
            if info['author'] and info['year']:
                ref_pairs.add((info['author'].strip().lower(), info['year']))
        unused_apa = [ref for ref in apa_refs_merged if
                    (extract_apa_reference_info_fixed(ref)['author'].strip().lower(),
                    extract_apa_reference_info_fixed(ref)['year']) not in apa_citation_pairs]
        uncited_apa = [f"{author}, {year}" for author, year in (apa_citation_pairs - ref_pairs)]

        # IEEEä¸»éµ: ç·¨è™Ÿ
        in_text_ieee_set = set(
            c['ref_number'].strip() for c in in_text_citations if c['format']=='IEEE' and c.get('ref_number')
        )
        ieee_ref_numbers = set()
        for ref in ref_paras:
            m = re.match(r'^\s*[\[ã€](\d+)[ã€‘\]]', ref)
            if m:
                ieee_ref_numbers.add(m.group(1).strip())
        unused_ieee_refs = [ref for ref in ref_paras if (
            (m := re.match(r'^\s*[\[ã€](\d+)[ã€‘\]]', ref)) and m.group(1).strip() not in in_text_ieee_set)]
        uncited_ieee = in_text_ieee_set - ieee_ref_numbers

        # çµ±ä¸€å±•ç¤ºï¼ˆä¸ç”¨åˆ†æ ¼å¼ï¼Œåªåˆ†æ¸…å–®é¡å‹ï¼‰
        tab1, tab2, tab3 = st.tabs(['æœªè¢«å¼•ç”¨æ–‡ç»','æœªåˆ—å‡ºå¼•ç”¨','åˆä½µé è¦½'])
        with tab1:
            count = 0
            for r in unused_apa:
                count += 1
                st.write(f"{count}. {r}")
            for r in unused_ieee_refs:
                count += 1
                st.write(f"{count}. {r}")
            if count == 0:
                st.success("æ‰€æœ‰åƒè€ƒæ–‡ç»éƒ½å·²è¢«å¼•ç”¨")

        with tab2:
            count = 0
            for c in uncited_apa:
                count += 1
                st.write(f"{count}. {c}")
            for num in uncited_ieee:
                count += 1
                st.write(f"{count}. IEEEç·¨è™Ÿ[{num}]")
            if count == 0:
                st.success("æ‰€æœ‰å¼•ç”¨éƒ½å‡ºç¾åœ¨åƒè€ƒæ–‡ç»")

        with tab3:
            for i, r in enumerate(apa_refs_merged[:10], 1):
                st.write(f"{i}. {r}")

        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                border-radius: 12px;
                padding: 20px;
                text-align: center;
                color: white;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            ">
                <div style="font-size: 18px; opacity: 0.9; margin-bottom: 6px;">åƒè€ƒæ–‡ç»ç¸½æ•¸</div>
                <div style="font-size: 28px; font-weight: bold;">{len(ref_info)}</div>
            </div>
            """, unsafe_allow_html=True)
        
        apa_refs = sum(1 for r in ref_info if r['format'] == 'APA')
        with col2:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
                border-radius: 12px;
                padding: 20px;
                text-align: center;
                color: white;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            ">
                <div style="font-size: 18px; opacity: 0.9; margin-bottom: 6px;">APA æ ¼å¼</div>
                <div style="font-size: 28px; font-weight: bold;">{apa_refs}</div>
            </div>
            """, unsafe_allow_html=True)
        
        ieee_refs = sum(1 for r in ref_info if r['format'] == 'IEEE')
        with col3:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #0066cc 0%, #0080ff 100%);
                border-radius: 12px;
                padding: 20px;
                text-align: center;
                color: white;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            ">
                <div style="font-size: 18px; opacity: 0.9; margin-bottom: 6px;">IEEE æ ¼å¼</div>
                <div style="font-size: 28px; font-weight: bold;">{ieee_refs}</div>
            </div>
            """, unsafe_allow_html=True)
        
        apalike_refs = sum(1 for r in ref_info if r['format'] == 'APA_LIKE')
        with col4:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #ff7675 0%, #ff9a3d 100%);
                border-radius: 12px;
                padding: 20px;
                text-align: center;
                color: white;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            ">
                <div style="font-size: 18px; opacity: 0.9; margin-bottom: 6px;">APA_LIKE</div>
                <div style="font-size: 28px; font-weight: bold;">{apalike_refs}</div>
            </div>
            """, unsafe_allow_html=True)
        
        unknown_refs = sum(1 for r in ref_info if r['format'] == 'Unknown')
        with col5:
            st.markdown(f"""
            <div style="
                background: linear-gradient(135deg, #95de64 0%, #b3e5fc 100%);
                border-radius: 12px;
                padding: 20px;
                text-align: center;
                color: #333;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            ">
                <div style="font-size: 18px; opacity: 0.9; margin-bottom: 6px;">æœªçŸ¥æ ¼å¼</div>
                <div style="font-size: 28px; font-weight: bold;">{unknown_refs}</div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ============ IEEE ç¨ç«‹å±•ç¤ºï¼ˆé¿å…å·¢ç‹€ expanderï¼‰============
        st.markdown("### ğŸ“– IEEE åƒè€ƒæ–‡ç»è©³ç´°è§£æ")
        
        ieee_list = [ref for ref in ref_info if ref['format'] == 'IEEE']
        
        if ieee_list:
            st.info(f"å…±æ‰¾åˆ° {len(ieee_list)} ç­† IEEE æ ¼å¼åƒè€ƒæ–‡ç»")
            
            for i, ref in enumerate(ieee_list, 1):
                ieee_data = extract_ieee_reference_full(ref['original'])
                
                type_icons = {
                    'Conference Paper': 'ğŸ“„',
                    'Journal Article': 'ğŸ“š',
                    'Book': 'ğŸ“–',
                    'Website/Online': 'ğŸŒ',
                    'Thesis/Dissertation': 'ğŸ“',
                    'Technical Report': 'ğŸ“‹',
                    'Patent': 'âš–ï¸',
                    'Unknown': 'â“'
                }
                icon = type_icons.get(ieee_data['source_type'], 'ğŸ“„')
                
                with st.expander(
                    f"{icon} [{ieee_data['ref_number']}] {ieee_data['source_type']} - {ieee_data['title'] or 'æœªæä¾›æ¨™é¡Œ'}",
                    expanded=False
                ):
                    if ieee_data['authors']:
                        st.markdown(f"**ğŸ‘¥ ä½œè€…**")
                        st.markdown(f"ã€€â””â”€ {ieee_data['authors']}")
                    
                    if ieee_data['title']:
                        st.markdown(f"**ğŸ“ æ¨™é¡Œ**")
                        st.markdown(f"ã€€â””â”€ {ieee_data['title']}")
                    
                    if ieee_data['source_type'] == 'Conference Paper':
                        if ieee_data['conference_name']:
                            st.markdown(f"**ğŸ¯ æœƒè­°åç¨±**")
                            st.markdown(f"ã€€â””â”€ {ieee_data['conference_name']}")
                    
                    elif ieee_data['source_type'] == 'Journal Article':
                        if ieee_data['journal_name']:
                            st.markdown(f"**ğŸ“– æœŸåˆŠåç¨±**")
                            st.markdown(f"ã€€â””â”€ {ieee_data['journal_name']}")
                        vol_issue = []
                        if ieee_data['volume']:
                            vol_issue.append(f"Vol. {ieee_data['volume']}")
                        if ieee_data['issue']:
                            vol_issue.append(f"No. {ieee_data['issue']}")
                        if vol_issue:
                            st.markdown(f"**ğŸ“Š å·æœŸ**")
                            st.markdown(f"ã€€â””â”€ {', '.join(vol_issue)}")
                    
                    elif ieee_data['source_type'] == 'Website/Online':
                        if ieee_data['url']:
                            st.markdown(f"**ğŸ”— URL**")
                            st.markdown(f"ã€€â””â”€ [{ieee_data['url']}]({ieee_data['url']})")
                        if ieee_data['access_date']:
                            st.markdown(f"**ğŸ“… å­˜å–æ—¥æœŸ**")
                            st.markdown(f"ã€€â””â”€ {ieee_data['access_date']}")
                    
                    time_info = []
                    if ieee_data['year']:
                        time_info.append(f"ğŸ“… å¹´ä»½ï¼š{ieee_data['year']}")
                    if ieee_data['month']:
                        time_info.append(f"ğŸ“† æœˆä»½ï¼š{ieee_data['month']}")
                    if time_info:
                        st.markdown(f"**â° æ™‚é–“è³‡è¨Š**")
                        st.markdown(f"ã€€â””â”€ {' | '.join(time_info)}")
                    
                    if ieee_data['pages']:
                        st.markdown(f"**ğŸ“„ é ç¢¼**")
                        st.markdown(f"ã€€â””â”€ pp. {ieee_data['pages']}")
                    
                    if ieee_data['doi']:
                        st.markdown(f"**ğŸ” DOI**")
                        st.markdown(f"ã€€â””â”€ {ieee_data['doi']}")
                    
                    st.markdown("**ğŸ“ åŸæ–‡**")
                    st.code(ieee_data['original'], language=None)
        else:
            st.info("æœªæ‰¾åˆ° IEEE æ ¼å¼åƒè€ƒæ–‡ç»")
        
        st.markdown("---")
        
        # ============ APA å’Œå…¶ä»–æ ¼å¼ ============
        st.markdown("### ğŸ“š APA èˆ‡å…¶ä»–æ ¼å¼åƒè€ƒæ–‡ç»")
        
        with st.expander("ğŸ“‹ æŸ¥çœ‹ APA / APA_LIKE / æœªçŸ¥æ ¼å¼å®Œæ•´è³‡è¨Š"):
            for i, ref in enumerate(ref_info, 1):
                if ref['format'] == 'APA':
                    title_display = ref['title'] if ref['title'] else "âŒ ç„¡æ³•æ“·å–"
                    st.markdown(f"### {i}. [APA]")
                    st.markdown(f"**ğŸ“ ä½œè€…**ï¼š{ref['author']}")
                    st.markdown(f"**ğŸ“„ æ¨™é¡Œ**ï¼š{title_display}")
                    st.markdown(f"**ğŸ“… å¹´ä»½**ï¼š{ref['year']}")
                    if ref.get('date'):
                        st.markdown(f"**ğŸ—“ï¸ æ™‚é–“**ï¼š{ref['date']}")
                    
                    st.text_area(
                        label="åŸæ–‡",
                        value=ref['original'],
                        height=80,
                        key=f"ref_original_apa_{len(st.session_state.reference_list)}_{i}",
                        disabled=True
                    )
                    st.markdown("---")
                        
                elif ref['format'] == 'APA_LIKE':
                    st.markdown(f"### {i}. [APA_LIKE]")
                    st.markdown(f"**ğŸ“… å¹´ä»½**ï¼š{ref['year']}")
                    st.text_area(
                        label="åŸæ–‡",
                        value=ref['original'],
                        height=80,
                        key=f"ref_original_apalike_{len(st.session_state.reference_list)}_{i}",
                        disabled=True
                    )
                    st.markdown("---")
                        
                elif ref['format'] == 'Unknown':
                    st.markdown(f"### {i}. [æœªçŸ¥æ ¼å¼]")
                    st.markdown("**âš ï¸ ç„¡æ³•è§£ææ ¼å¼**")
                    st.text_area(
                        label="åŸæ–‡",
                        value=ref['original'],
                        height=80,
                        key=f"ref_original_unknown_{len(st.session_state.reference_list)}_{i}",
                        disabled=True
                    )
                    st.markdown("---")
                    
                elif ref['format'] == 'APA_LIKE':
                    st.markdown(f"### {i}. [APA_LIKE]")
                    st.markdown(f"**ğŸ“… å¹´ä»½**ï¼š{ref['year']}")
                    st.text_area(
                        label="åŸæ–‡",
                        value=ref['original'],
                        height=80,
                        key=f"ref_original_apalike_{i}",
                        disabled=True
                    )
                    st.markdown("---")
                    
                elif ref['format'] == 'Unknown':
                    st.markdown(f"### {i}. [æœªçŸ¥æ ¼å¼]")
                    st.markdown("**âš ï¸ ç„¡æ³•è§£ææ ¼å¼**")
                    st.text_area(
                        label="åŸæ–‡",
                        value=ref['original'],
                        height=80,
                        key=f"ref_original_unknown_{i}",
                        disabled=True
                    )
                    st.markdown("---")
    else:
        st.warning("ç„¡åƒè€ƒæ–‡ç»æ®µè½å¯ä¾›åˆ†æ")

st.markdown("---")
st.markdown("""
---
ğŸ“Œ **ä½¿ç”¨æç¤º**ï¼š
- ä¸Šå‚³ PDF/Word æª”æ¡ˆå¾Œï¼Œç³»çµ±æœƒè‡ªå‹•è§£æä¸¦æš«å­˜è³‡æ–™
- ä½¿ç”¨å´é‚Šæ¬„çš„ã€Œè³‡æ–™ç®¡ç†ã€åŠŸèƒ½ä¾†åŒ¯å‡º/åŒ¯å…¥ JSON
- JSON è³‡æ–™å¯ç”¨æ–¼å¾ŒçºŒèˆ‡å¤–éƒ¨ API æ¯”å°
""")

# ==================== æŸ¥çœ‹æš«å­˜è³‡æ–™ ====================
if st.session_state.in_text_citations or st.session_state.reference_list:
    with st.expander("ğŸ” æŸ¥çœ‹å®Œæ•´æš«å­˜è³‡æ–™ï¼ˆJSON æ ¼å¼ï¼‰"):
        st.json({
            "in_text_citations": st.session_state.in_text_citations,
            "reference_list": st.session_state.reference_list,
            "verified_references": st.session_state.verified_references
        })
